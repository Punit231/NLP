{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee7c0ab",
   "metadata": {},
   "source": [
    "Practical - 3 : Write a program to extract features from text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6439b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddfcafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "documents = [\n",
    "    \"Natural Language Processing enables computers to understand text.\",\n",
    "    \"Machine learning is a part of artificial intelligence.\",\n",
    "    \"Text data requires preprocessing before model training.\",\n",
    "    \"Understanding human language is the goal of NLP.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a9ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Bag of Words (BoW):\n",
      "   artificial  before  computers  data  enables  goal  human  intelligence  \\\n",
      "0           0       0          1     0        1     0      0             0   \n",
      "1           1       0          0     0        0     0      0             1   \n",
      "2           0       1          0     1        0     0      0             0   \n",
      "3           0       0          0     0        0     1      1             0   \n",
      "\n",
      "   is  language  ...  part  preprocessing  processing  requires  text  the  \\\n",
      "0   0         1  ...     0              0           1         0     1    0   \n",
      "1   1         0  ...     1              0           0         0     0    0   \n",
      "2   0         0  ...     0              1           0         1     1    0   \n",
      "3   1         1  ...     0              0           0         0     0    1   \n",
      "\n",
      "   to  training  understand  understanding  \n",
      "0   1         0           1              0  \n",
      "1   0         0           0              0  \n",
      "2   0         1           0              0  \n",
      "3   0         0           0              1  \n",
      "\n",
      "[4 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Bag of Words (CountVectorizer)\n",
    "# Bag of Words --> Counts word occurrences. Simple but ignores meaning/context.\n",
    "print(\"ðŸ”¹ Bag of Words (BoW):\")\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame for better view\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "980bd656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ TF-IDF:\n",
      "   artificial  before  computers  data  enables  goal  human  intelligence  \\\n",
      "0         0.0    0.00       0.37  0.00     0.37  0.00   0.00           0.0   \n",
      "1         0.4    0.00       0.00  0.00     0.00  0.00   0.00           0.4   \n",
      "2         0.0    0.39       0.00  0.39     0.00  0.00   0.00           0.0   \n",
      "3         0.0    0.00       0.00  0.00     0.00  0.38   0.38           0.0   \n",
      "\n",
      "     is  language  ...  part  preprocessing  processing  requires  text   the  \\\n",
      "0  0.00      0.29  ...   0.0           0.00        0.37      0.00  0.29  0.00   \n",
      "1  0.32      0.00  ...   0.4           0.00        0.00      0.00  0.00  0.00   \n",
      "2  0.00      0.00  ...   0.0           0.39        0.00      0.39  0.31  0.00   \n",
      "3  0.30      0.30  ...   0.0           0.00        0.00      0.00  0.00  0.38   \n",
      "\n",
      "     to  training  understand  understanding  \n",
      "0  0.37      0.00        0.37           0.00  \n",
      "1  0.00      0.00        0.00           0.00  \n",
      "2  0.00      0.39        0.00           0.00  \n",
      "3  0.00      0.00        0.00           0.38  \n",
      "\n",
      "[4 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2. TF-IDF\n",
    "# TF-IDF --> Adjusts for common vs rare terms across documents. Better for relevance.\n",
    "print(\"\\nðŸ”¹ TF-IDF:\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame for better view\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(tfidf_df.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

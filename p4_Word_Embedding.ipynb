{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ec97ea",
   "metadata": {},
   "source": [
    "Practical - 4 : Implement word embedding using Word2Vec / GloVe / fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05abcc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28cb8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus\n",
    "corpus = [\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Word embeddings like Word2Vec capture the context of a word in a document.\",\n",
    "    \"They are more efficient than traditional sparse representations like Bag of Words.\",\n",
    "    \"Deep learning has significantly improved NLP models in recent years.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Tokenized Corpus:\n",
      "[['natural', 'language', 'processing', 'enables', 'computers', 'to', 'understand', 'human', 'language', '.'], ['word', 'embeddings', 'like', 'word2vec', 'capture', 'the', 'context', 'of', 'a', 'word', 'in', 'a', 'document', '.'], ['they', 'are', 'more', 'efficient', 'than', 'traditional', 'sparse', 'representations', 'like', 'bag', 'of', 'words', '.'], ['deep', 'learning', 'has', 'significantly', 'improved', 'nlp', 'models', 'in', 'recent', 'years', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize sentences into words\n",
    "tokenized_corpus = [word_tokenize(sent.lower()) for sent in corpus]\n",
    "print(\"ðŸ”¹ Tokenized Corpus:\")\n",
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50269b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "461d3c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Vector for 'language':\n",
      "[ 8.13227147e-03 -4.45733406e-03 -1.06835726e-03  1.00636482e-03\n",
      " -1.91113955e-04  1.14817743e-03  6.11386076e-03 -2.02715401e-05\n",
      " -3.24596534e-03 -1.51072862e-03  5.89729892e-03  1.51410222e-03\n",
      " -7.24261976e-04  9.33324732e-03 -4.92128357e-03 -8.38409644e-04\n",
      "  9.17541143e-03  6.74942741e-03  1.50285603e-03 -8.88256077e-03\n",
      "  1.14874600e-03 -2.28825561e-03  9.36823711e-03  1.20992784e-03\n",
      "  1.49006362e-03  2.40640994e-03 -1.83600665e-03 -4.99963388e-03\n",
      "  2.32429506e-04 -2.01418041e-03  6.60093315e-03  8.94012302e-03\n",
      " -6.74754381e-04  2.97701475e-03 -6.10765442e-03  1.69932481e-03\n",
      " -6.92623248e-03 -8.69402662e-03 -5.90020278e-03 -8.95647518e-03\n",
      "  7.27759488e-03 -5.77203138e-03  8.27635173e-03 -7.24354526e-03\n",
      "  3.42167495e-03  9.67499893e-03 -7.78544787e-03 -9.94505733e-03\n",
      " -4.32914635e-03 -2.68313056e-03 -2.71289347e-04 -8.83155130e-03\n",
      " -8.61755759e-03  2.80021061e-03 -8.20640661e-03 -9.06933658e-03\n",
      " -2.34046578e-03 -8.63180775e-03 -7.05664977e-03 -8.40115082e-03\n",
      " -3.01328895e-04 -4.56429832e-03  6.62717456e-03  1.52716041e-03\n",
      " -3.34147573e-03  6.10897178e-03 -6.01328490e-03 -4.65616956e-03\n",
      " -7.20750913e-03 -4.33658017e-03 -1.80932996e-03  6.48964290e-03\n",
      " -2.77039292e-03  4.91896737e-03  6.90444233e-03 -7.46370573e-03\n",
      "  4.56485013e-03  6.12697843e-03 -2.95447465e-03  6.62502181e-03\n",
      "  6.12587947e-03 -6.44348515e-03 -6.76455162e-03  2.53895880e-03\n",
      " -1.62381888e-03 -6.06512791e-03  9.49920900e-03 -5.13014663e-03\n",
      " -6.55409694e-03 -1.19885204e-04 -2.70142802e-03  4.44400299e-04\n",
      " -3.53745813e-03 -4.19330609e-04 -7.08615757e-04  8.22820642e-04\n",
      "  8.19481723e-03 -5.73670724e-03 -1.65952800e-03  5.57160750e-03]\n"
     ]
    }
   ],
   "source": [
    "# Check vector for a word\n",
    "print(\"\\nðŸ”¹ Vector for 'language':\")\n",
    "print(model.wv['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Words similar to 'language':\n",
      "[('are', 0.34885063767433167), ('deep', 0.3040151596069336), ('has', 0.17751169204711914), ('the', 0.16392920911312103), ('significantly', 0.16265255212783813), ('of', 0.1458953320980072), ('than', 0.11254310607910156), ('document', 0.11074695736169815), ('words', 0.0943744108080864), ('years', 0.07480879127979279)]\n"
     ]
    }
   ],
   "source": [
    "# Find similar words\n",
    "print(\"\\nðŸ”¹ Words similar to 'language':\")\n",
    "print(model.wv.most_similar('language'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d45a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Similarity between 'language' and 'word':\n",
      "0.034789123\n"
     ]
    }
   ],
   "source": [
    "# Check similarity between two words\n",
    "print(\"\\nðŸ”¹ Similarity between 'language' and 'word':\")\n",
    "print(model.wv.similarity('language', 'word'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
